# Chapter 1: Transformer

Reading Materials:
1. Attention is all you need: https://arxiv.org/pdf/1706.03762 ï¼ˆvideo analysis: https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.337.search-card.all.click&vd_source=75e16b30403690b6ad4ccdb9c2dbde46)
2. Attention Blog post: https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
3. Illustrated Transformer Blogpost: https://jalammar.github.io/illustrated-transformer/

Practical Implementation:
1. Andrej Karpathy: Let's build GPT: from scratch, in code, spelled out.
 https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6067s
 
 Solution to Deep Learning Curriculum Chapter 1:
 